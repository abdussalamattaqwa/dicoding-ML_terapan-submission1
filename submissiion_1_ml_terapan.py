# -*- coding: utf-8 -*-
"""Submissiion 1 ML Terapan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RyyEwWX2KhrSN6LfueH3VVjKQZ_fXJUx

Nama : Abd Salam At Taqwa

Sumber dataset : https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition

#Laporan Proyek Machine Learning - Abd Salam At Taqwa

##Domain Proyek

###Latar Belakang

Pola makan dalam kehidupan seseorang harus lebih diperhatikan karena pola makan yang tidak sehat dapat menyebabkan berbagai macam penyakit, salah satunya adalah obesitas. Obesitas merupakan suatu kondisi dimana lemak menumpuk atau berlebihan sehingga dapat berdampak buruk bagi kesehatan. Kegagalan untuk segera mengatasi obesitas dapat meningkatkan risiko penyakit jantung, tekanan darah tinggi, dan diabetes.

Suatu cara untuk mengatasi obesitas adalah menjaga dan memonitor pola makan dan aktifitas kondisi fisik dalam kehidupan sehari-hari. Ada beberapa faktor yang mempengaruhi pola makan seseorang, diantaranya adalah Frekuensi konsumsi makanan berkalori tinggi (FAVC), Frekuensi konsumsi sayuran (FCVC), Jumlah makanan utama (NCP), Konsumsi makanan di antara waktu makan (CAEC), Konsumsi air setiap hari (CH20), dan Konsumsi alkohol (CALC).

Selain dari pola makan faktor-faktor yang terkait pada kondisi fisik adalah: Pemantauan konsumsi kalori (SCC), Frekuensi aktivitas fisik (FAF), Waktu penggunaan menggunakan perangkat teknologi (TUE), Transportasi yang digunakan (MTRANS), variabel lain yang diperoleh adalah: Jenis Kelamin, Usia, Tinggi dan Berat Badan.

Faktor-faktor pola makan dan kondisi fisik tersebut perlu di perhatikan lebih baik untuk mencegah obesitas. Apabila faktor tersebut tidak diperhatikan dapat dengan mudah mengalami obesitas tanpa disadari. Oleh karena itu perlunya sebuah model yang dapat memprediksi obesitas seseorang berdasarkan faktor-faktor atau atribut tersebut. Hal ini dapat memudahkan manusia untuk memonitoring dan mencegah atau memperbaiki lebih awal ketika pola makan dan kondisi fisik tidak baik.

##Business Understanding

Proyek ini dibangun untuk mengatur pola makan dan kondisi fisik seseorang untuk mencegah obesitas. Data dari pola makan dan kondisi fisik dapat digunakan untuk memprediksi tingkatan dari obesitas seseorang. Hasil dari prediksi obesitas dapat dijadikan sebagai acuan untuk mengatur atau memperbaiki pola makan dan kondisi fisik sebelum penyakit obesitas bertambah parah.

##Problem Statements

Menjelaskan pernyataan masalah latar belakang:

* Faktor atau fitur apa yang paling mempengaruhi obesitas seseorang?
* Bagaimana karakteristik obesitas seseorang dengan pola makan dan kondisi fisik tertentu?

##Goals
* Mengetahui faktor yang paling berpengaruh terhadap obesitas seseorang
* Membangun sebuah model yang dapat memprediksi tingkat obesitas seseorang berdasarkan riwayat pola makan dan kondisi fisik seseorang

## Solution statements

* Melakukan Exploratory Data Analysis terhadap semua faktor atau variabel untuk menemumak varibel yang paling berpengaruh terhadap penentuan tingkat obesitas seseorang
* Membangun 3 model machine learning sederhana dan memilih yang terbaik untuk memprediksi obesitas berdasarkan riwayat pola makan dan kondisi fisik

##Data Understanding & Removing Outlier

Dataset yang digunakan dalam proyek ini merupakan data pola makanan dan kondisi fisik yang memiliki kriteria tingkat obesitasnya masing-masing. Dataset ini sudah tersedia dan dapat diunduh pada [UCI Machine learning](https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition).
"""

# menginstall package ucimlrepo
!pip install ucimlrepo

# Mengimport librari yang ucimlrepo yang telah diinstall sebelumnya
from ucimlrepo import fetch_ucirepo

support2 = fetch_ucirepo(id=544)
# data (as pandas dataframes)
X = support2.data.features
y = support2.data.targets

# metadata
print(support2.metadata)

# variable information
print(support2.variables)

"""Berikut informasi pada dataset :

* Dataset memiliki format CSV (Comma-Seperated Values).
* Dataset memiliki 2111 sample dengan 16 fitur.
* Dataset memiliki 4 fitur bertipe categorical 6 fitur bertipe data continuous, 4 bertipe data binary, dan 2 tipe data integer.
* Tidak ada missing value dalam dataset.

##Variable - variable pada dataset

* Gender : Jenis kelamin
* Age : Umur  
* Height : Tinggi badan
* Weight : Berat badan
* family_history_with_overweight : riwayat keluarga dengan kelebihan berat badan
* FAVC : Sering konsumsi makanan berkalori tinggi
* FCVC : Frekuensi konsumsi sayuran
* NCP  : Jumlah makanan utama
* CAEC : Konsumsi makanan di antara waktu makan
* SMOKE : Perokok atau tidak merokok
* CH2O : Konsumsi air setiap hari
* SCC  : Pemantauan konsumsi kalori
* FAF : Frekuensi aktivitas fisik
* TUE  : Waktu menggunakan perangkat teknologi
* CALC : Konsumsi alkohol
* MTRANS : Transportasi yang digunakan
* NObeyesdad  : Label tingkat obesitas

## Exploratory Data Analysis

### Assessing Data
"""

# Mengimport librari yang dibutuhkan
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

# Melihat informasi dataset
X.info()

# Berdasarkan hasil diatas perlunya mengubah tipe data objek pada fitur-fitur tersebut menjadi tipe data kategori

# Melihat jumlah nilai null pada masing-masing kolom
X.isna().sum()

# Melihat deskripsi data untuk menganalisis penyebaran data masing-masing fitur dengan tipe data integeruntuk melihat apakah ada anomali data
# Berdasarkan hasil didapatkan bahwa tidak terdapat data anomali atau data tidak jelas pada dataset
X.describe()

# Visualisasi jenis kelamin yang dominan pada data untuk melihat ukuran data berdasarkan gender
plt.figure(figsize=(10,6))
sns.countplot(
    y="Gender",
    # order=X["Gender"].value_counts().index,
    data=X)

plt.title('Ukuran Data Berdasarkan Gender')
plt.xlabel('Gender')
plt.ylabel('Jumlah Data')
plt.show()

"""Berdasarkan hasil visualisasi diatas dapat dilihat bahwa data termasuk seimbang karena data laki-laki dan perempuan memiliki ukuran yang hampir sama

## Data Preparation
"""

from sklearn.preprocessing import LabelEncoder

to_cat = X.loc[:, X.nunique() < 8].columns
to_cat

# Mengkonfersi data-data objek yang bersifat kategorikal menjadi numeric yang dapat dengan mudah dipahami model

encoder = LabelEncoder()

columns_to_encode = X.loc[:, X.nunique() < 8].columns

for column in columns_to_encode:
    X[column] = encoder.fit_transform(X[column])

X.head()

y.head()

y['NObeyesdad'] = encoder.fit_transform(y['NObeyesdad'])

y.head()

"""## Memisahkan data latih dan data uji"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Modeling"""

# Menggunakan algoritma grid search untuk hyperparameter tunning

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import ShuffleSplit

from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor

from sklearn.metrics import mean_squared_error

algo_params = {
    'knn': {
        'model': KNeighborsRegressor(),
        'params': {
            'n_neighbors': [5, 7, 9, 11, 13, 15],
        }
    },
    'boosting': {
        'model': AdaBoostRegressor(),
        'params': {
            'learning_rate' : [0.1, 0.01, 0.001],
            'n_estimators': [25, 50, 100],
            'random_state': [11, 33, 55]
        }
    },
    'random_forest': {
        'model': RandomForestRegressor(),
        'params': {
            'n_estimators': [25, 50, 100],
            'max_depth' : [8, 16, 32],
            'random_state': [11, 33, 55],
        }
    }

}

scores = []
cv = ShuffleSplit(n_splits=5, test_size=0.05, random_state=123)
for algo_name, config in algo_params.items():
    gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)
    gs.fit(X,y.values.ravel())
    scores.append({
        'model': algo_name,
        'best_score': gs.best_score_,
        'best_params': gs.best_params_
    })

result = pd.DataFrame(scores,columns=['model','best_score','best_params'])

result

"""Menjalankan model dengan parameter terbaik"""

models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

RF = RandomForestRegressor(n_estimators=25, max_depth=32, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train.values.ravel())

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

boosting = AdaBoostRegressor(learning_rate=0.1, random_state=55, n_estimators= 100)
boosting.fit(X_train, y_train.values.ravel())
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""##Evaluasi Model"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[5:10].copy()
pred_dict = {'y_true':y_test[5:10].values.ravel()}


for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pred_dict['prediksi_KNN'] = pred_dict['prediksi_KNN'].flatten()
pd.DataFrame(pred_dict)